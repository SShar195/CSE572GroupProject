{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./geophone/geophone-sensor-data.csv\")\n",
    "\n",
    "dataset_sorted = dataset.sort_values(by=[\"name\", \"timestamp\"], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "og = sns.FacetGrid(dataset_sorted)\n",
    "og.map(plt.hist, 'mean', bins=20)\n",
    "\n",
    "og.set_axis_labels(\"Mean\", \"Frequency\")\n",
    "og.set_titles(col_template=\"{col_name}\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "og.figure.suptitle(\"Distribution of Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset_sorted, test_size=0.5, random_state=42, shuffle=True)\n",
    "print(train.head())\n",
    "print('_'*40)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = sns.FacetGrid(train)\n",
    "train_g.map(plt.hist, 'mean', bins=20)\n",
    "train_g.set_axis_labels(\"Mean\", \"Frequency\")\n",
    "train_g.set_titles(col_template=\"{col_name}\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "train_g.figure.suptitle(\"Distribution of Training Mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = sns.FacetGrid(test)\n",
    "test_g.map(plt.hist, 'mean', bins=20)\n",
    "\n",
    "test_g.set_axis_labels(\"Mean\", \"Frequency\")\n",
    "test_g.set_titles(col_template=\"{col_name}\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "test_g.figure.suptitle(\"Distribution of Test Mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514928bc",
   "metadata": {},
   "source": [
    "Cannot use person as a afeature due to below inconsistencies. We have to look at the data holistically. \n",
    "\n",
    "Test if there are outliers or noise in the data \n",
    "\n",
    "Binning and standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67eefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'energy', alpha=.5, bins=20)\n",
    "grid.add_legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'dominant_freq', 'activity', alpha=.5)\n",
    "grid.add_legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.triplot, 'min', 'max', alpha=.5)\n",
    "grid.add_legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10028a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.ecdf, 'max', alpha=.5)\n",
    "grid.map(plt.ecdf, 'min', alpha=.5, color='red')\n",
    "grid.map(plt.ecdf, 'mean', alpha=.5, color='green')\n",
    "grid.add_legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'timestamp' column is a proper datetime object\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'timestamp', 'max', alpha=.5, color='blue', s=10)\n",
    "grid.map(plt.scatter, 'timestamp', 'min', alpha=.5, color='red', s=10)\n",
    "# grid.map(plt.plot('timestamp', max, label='Max Value', color='blue'))\n",
    "# grid.map(plt.plot('timestamp', min, label='Min Value', color='red'))\n",
    "\n",
    "# Add titles and labels for clarity\n",
    "# plt.title('Max and Min Values Over Time')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "# plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24225adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'timestamp', 'max', alpha=.5, color='blue', s=10)\n",
    "grid.map(plt.scatter, 'timestamp', 'min', alpha=.5, color='red', s=10)\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'timestamp' column is a proper datetime object\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train, col='name', row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "\n",
    "train_emir = train[train['name'] == 'Emir']\n",
    "\n",
    "\n",
    "grid = sns.FacetGrid(train_emir, row='activity', height=2.2, aspect=1.6)\n",
    "\n",
    "\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)\n",
    "\n",
    "grid.set_titles(row_template='{row_name} Emir')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "\n",
    "train_yusuf = train[train['name'] == 'Yusuf']\n",
    "\n",
    "\n",
    "grid = sns.FacetGrid(train_yusuf, row='activity', height=2.2, aspect=1.6)\n",
    "\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)\n",
    "\n",
    "grid.set_titles(row_template='{row_name} Yusuf')\n",
    "plt.show() # To display the plot, if not in a notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "\n",
    "train_enes = train[train['name'] == 'Enes']\n",
    "grid = sns.FacetGrid(train_enes, row='activity', height=2.2, aspect=1.6)\n",
    "\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)\n",
    "\n",
    "grid.set_titles(row_template='{row_name} Enes')\n",
    "plt.show() # To display the plot, if not in a notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "train_furkan = train[train['name'] == 'Furkan']\n",
    "grid = sns.FacetGrid(train_furkan, row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)\n",
    "grid.set_titles(row_template='{row_name} Furkan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "train_alihan = train[train['name'] == 'Alihan']\n",
    "grid = sns.FacetGrid(train_alihan, row='activity', height=2.2, aspect=1.6)\n",
    "grid.map(plt.scatter, 'timestamp', 'mean', alpha=.5, color='green', s=10)\n",
    "grid.set_titles(row_template='{row_name} Alihan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ceb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relation between Mean and Movement apply train at later date\n",
    "train['range'] = train['max'] - train['min']\n",
    "train['mean_to_range_ratio'] = np.where(\n",
    "    train['range'] != 0,(train['mean'] - train['min']) / train['range'], 0.5\n",
    ")\n",
    "#confirnmation printout\n",
    "print(train[['mean', 'min', 'max', 'range', 'mean_to_range_ratio']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip Out Useless Info apply to train later\n",
    "KEEP_COLUMNS = ['max', 'min', 'mean', 'range', 'mean_to_range_ratio', 'activity', 'name']\n",
    "train_processed = train[KEEP_COLUMNS].copy()\n",
    "print(train_processed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e59b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_counts = train.groupby('name')['activity'].value_counts().unstack(fill_value=0)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "activity_counts.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('Distribution of Activities Per Person (Training Set)')\n",
    "ax.set_xlabel('Person (Name)')\n",
    "ax.set_ylabel('Count of Sensor Readings')\n",
    "ax.legend(title='Activity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "grid_box = sns.FacetGrid(train, col='name', row='activity', height=3, aspect=1.2)\n",
    "grid_box.map(sns.boxplot, 'range', orient='h', color='skyblue')\n",
    "grid_box.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "grid_box.set_axis_labels(\"Range (Max - Min)\", \"\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "grid_box.figure.suptitle(\"Distribution of New Feature 'Range' by Person and Activity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12917cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'range' not in train.columns:\n",
    "    train['range'] = train['max'] - train['min']\n",
    "    train['mean_to_range_ratio'] = np.where(\n",
    "        train['range'] != 0,\n",
    "        (train['mean'] - train['min']) / train['range'],\n",
    "        0.5\n",
    "    )\n",
    "test['range'] = test['max'] - test['min']\n",
    "test['mean_to_range_ratio'] = np.where(\n",
    "    test['range'] != 0,\n",
    "    (test['mean'] - test['min']) / test['range'],\n",
    "    0.5\n",
    ")\n",
    "\n",
    "all_train_cols = train.columns.tolist()\n",
    "metadata_cols = ['activity', 'name', 'timestamp'] \n",
    "KEEP_COLUMNS = [col for col in all_train_cols if col not in ['timestamp']]\n",
    "\n",
    "# Create processed datasets\n",
    "train_processed = train[KEEP_COLUMNS].copy()\n",
    "test_processed = test[KEEP_COLUMNS].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da65edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_processed.drop(['activity', 'name'], axis=1, errors='ignore')\n",
    "y_train = train_processed['activity']\n",
    "\n",
    "#Prepare test data \n",
    "X_test = test_processed.drop(['activity', 'name'], axis=1, errors='ignore')\n",
    "y_test = test_processed['activity']\n",
    "common_features = X_train.columns.intersection(X_test.columns).tolist()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  \n",
    "y_test_encoded = le.transform(y_test)      \n",
    "\n",
    "\n",
    "print(f\"Original Activities: {le.classes_}\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"Features used: {list(X_train.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train_encoded)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"\\nLogistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_lr, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Logistic Regression (One-vs-Rest)\": LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine (LinearSVC)\": LinearSVC(max_iter=10000, random_state=42),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    test_score = model.score(X_test, y_test_encoded)\n",
    "    train_score = model.score(X_train, y_train_encoded)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name, \n",
    "        'Train Accuracy': round(train_score * 100, 2),\n",
    "        'Test Accuracy': round(test_accuracy * 100, 2),\n",
    "        'Overfitting Gap': round((train_score - test_accuracy) * 100, 2)\n",
    "    })\n",
    "    \n",
    "    trained_models[name] = model\n",
    "\n",
    "model_results = pd.DataFrame(results).sort_values(by='Test Accuracy', ascending=False)\n",
    "\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ab4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "best_model_name = model_results.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nANALYSIS OF BEST MODEL: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {model_results.iloc[0]['Test Accuracy']}%\")\n",
    "\n",
    "#feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = pd.Series(best_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=importances.values, y=importances.index, color='purple')\n",
    "    plt.title(f'Feature Importance ({best_model_name})')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('True Activity')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a311d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_cols_new = ['dominant_freq', 'energy', 'std_dev', 'skewness', 'min', 'max']\n",
    "\n",
    "available_features = [f for f in rf_feature_cols_new if f in X_train.columns]\n",
    "missing_features = [f for f in rf_feature_cols_new if f not in X_train.columns]\n",
    "\n",
    "if len(rf_feature_cols_new) > 0:\n",
    "    #new feature subset\n",
    "    X_train_rf_new = X_train[rf_feature_cols_new]\n",
    "    X_test_rf_new = X_test[rf_feature_cols_new]\n",
    "    rf_model_new = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model_new.fit(X_train_rf_new, y_train_encoded)\n",
    "    y_pred_rf_new = rf_model_new.predict(X_test_rf_new)\n",
    "    \n",
    "    rf_new_accuracy = accuracy_score(y_test_encoded, y_pred_rf_new)\n",
    "    print(f\"\\nRandom Forest (Custom Feature Set) Accuracy: {rf_new_accuracy:.4f}\")\n",
    "    print(f\"Features used: {rf_feature_cols_new}\")\n",
    "    print(\"\\nRandom Forest (Custom Feature Set) Classification Report:\")\n",
    "    print(classification_report(y_test_encoded, y_pred_rf_new, target_names=le.classes_))\n",
    "    \n",
    "    rf_new_importances = pd.Series(rf_model_new.feature_importances_, \n",
    "                                    index=rf_feature_cols_new).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=rf_new_importances.values, y=rf_new_importances.index, color='forestgreen')\n",
    "    plt.title('Feature Importance (Custom Random Forest)')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "    \n",
    "    # Final comparison\n",
    "    lr_baseline_accuracy = lr_accuracy\n",
    "    best_comparison_accuracy = model_results.iloc[0]['Test Accuracy'] / 100\n",
    "    \n",
    "    comparison_summary = pd.DataFrame({\n",
    "        'Model': [\n",
    "            'Logistic Regression (Baseline)',\n",
    "            f'{best_model_name} (All Features)',\n",
    "            f'Random Forest (Custom Features: {len(rf_feature_cols_new)})'\n",
    "        ],\n",
    "        'Accuracy': [\n",
    "            round(lr_baseline_accuracy, 4),\n",
    "            round(best_comparison_accuracy, 4),\n",
    "            round(rf_new_accuracy, 4)\n",
    "        ],\n",
    "        'Accuracy %': [\n",
    "            round(lr_baseline_accuracy * 100, 2),\n",
    "            round(best_comparison_accuracy * 100, 2),\n",
    "            round(rf_new_accuracy * 100, 2)\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nFinal Comparison:\")\n",
    "    print(comparison_summary.to_string(index=False))\n",
    "    \n",
    "    improvement_over_baseline = (rf_new_accuracy - lr_baseline_accuracy) * 100\n",
    "    improvement_over_best = (rf_new_accuracy - best_comparison_accuracy) * 100\n",
    "    \n",
    "    print(f\"\\nBaseline: {lr_baseline_accuracy:.4f}\")\n",
    "    print(f\"Best Model ({best_model_name}): {best_comparison_accuracy:.4f}\")\n",
    "    print(f\"Custom RF: {rf_new_accuracy:.4f}\")\n",
    "    print(f\"Improvement over baseline: {improvement_over_baseline:+.2f}pp\")\n",
    "    \n",
    "    if rf_new_accuracy > best_comparison_accuracy:\n",
    "        print(f\"Improvement over best model: {improvement_over_best:+.2f}pp\")\n",
    "    else:\n",
    "        print(f\"Difference from best model: {improvement_over_best:.2f}pp\")\n",
    "else:\n",
    "    print(f\"\\nERROR: No specified features available. Available: {list(X_train.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df062a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# hyperparameter tuning\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_grid.fit(X_train, y_train_encoded)\n",
    "print(f\"Best RF parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF CV score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "rf_tuned_accuracy = rf_grid.score(X_test, y_test_encoded)\n",
    "print(f\"Tuned RF Test Accuracy: {rf_tuned_accuracy:.4f}\")\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train_encoded)\n",
    "gb_accuracy = gb_model.score(X_test, y_test_encoded)\n",
    "print(f\"Gradient Boosting Test Accuracy: {gb_accuracy:.4f}\")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_grid.best_estimator_),\n",
    "        ('gb', gb_model),\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train_scaled, y_train_encoded)\n",
    "voting_accuracy = voting_clf.score(X_test_scaled, y_test_encoded)\n",
    "print(f\"Voting Ensemble Test Accuracy: {voting_accuracy:.4f}\")\n",
    "\n",
    "# Xboost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "xgb_accuracy = xgb_model.score(X_test, y_test_encoded)\n",
    "print(f\"XGBoost Test Accuracy: {xgb_accuracy:.4f}\")\n",
    "\n",
    "optimization_results = pd.DataFrame({\n",
    "    'Method': [\n",
    "        'Baseline (Logistic Regression)',\n",
    "        f'Best Original Model ({best_model_name})',\n",
    "        'Tuned Random Forest',\n",
    "        'Gradient Boosting',\n",
    "        'Voting Ensemble',\n",
    "        'XGBoost' if xgb_accuracy else 'XGBoost (N/A)'\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        round(lr_accuracy, 4),\n",
    "        round(best_comparison_accuracy, 4),\n",
    "        round(rf_tuned_accuracy, 4),\n",
    "        round(gb_accuracy, 4),\n",
    "        round(voting_accuracy, 4),\n",
    "        round(xgb_accuracy, 4) if xgb_accuracy else 0\n",
    "    ]\n",
    "}).sort_values(by='Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(optimization_results.to_string(index=False))\n",
    "\n",
    "best_optimization = optimization_results.iloc[0]\n",
    "print(f\"\\nBest Method: {best_optimization['Method']}\")\n",
    "print(f\"Best Accuracy: {best_optimization['Test Accuracy']:.4f}\")\n",
    "print(f\"Improvement over baseline: {(best_optimization['Test Accuracy'] - lr_accuracy)*100:+.2f}pp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
